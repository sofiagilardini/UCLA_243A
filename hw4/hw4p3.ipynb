{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 4, Problem 3 Classification on simulated data\n",
    "\n",
    "ECE C143A/C243A, Spring Quarter 2023, Prof. J.C. Kao, TAs T. Monsoor, R. Gore, D. Singla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "We will now apply the results of Problems 1 and 2 to simulated data. The dataset can be found on BruinLearn as ps4_simdata.mat. \n",
    "\n",
    "The following describes the data format. The .mat file has a single variable named 'trial', which is a structure of dimensions (20 data points) × (3 classes). The nth data point for the kth class is denoted via:\n",
    "\n",
    "`data['trial'][n][k][0]` where n = 0,...,19 and k = 0,1,2 are the data points and classes respectively.  The `[0]` after `[n][k]` is an artifact of how the `.mat` file is imported into Python.  You can get a clearer sense of this below in the plotting scripts.\n",
    "\n",
    "To make the simulated data as realistic as possible, the data are non-negative integers, so one can think of them as spike counts. With this analogy, there are D = 2 neurons and K = 3 stimulus conditions.\n",
    "\n",
    "Please follow steps (a)–(e) below for each of the three models. The result of this problem should be three separate plots, one for each model. These plots will be similar in spirit to Figure 4.5 in PRML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special\n",
    "import scipy.io as sio\n",
    "import math\n",
    "\n",
    "# Load matplotlib images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Reloading any code written in external .py files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "data = sio.loadmat('ps4_simdata.mat') # load the .mat file.\n",
    "NumData = data['trial'].shape[0]\n",
    "NumClass = data['trial'].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Plot the data points\n",
    "\n",
    "Here, to get you oriented on the dataset, we'll give you code that plots the data points.  You do not have to write any new code here, but you should review this code to understand it, since we'll ask you to make plots in later parts of the notebook.\n",
    "\n",
    "Here, we plot the data points in a two-dimensional space. For classes k = 1, 2, 3, we use a red ×, green +, and blue ∗ for each data point, respectively. The axis limits of the plot are between 0 and 20.  You should use these axes bounds for the rest of the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'x_2')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a\n",
    "plt.figure(figsize=(7,7))\n",
    "#====================================================#\n",
    "# PLOTTING CODE BELOW\n",
    "#====================================================#\n",
    "dataArr =  np.zeros((NumClass,NumData ,2)) # dataArr contains the points\n",
    "for classIX in range(NumClass):\n",
    "    for dataIX in range(NumData):\n",
    "        x = data['trial'][dataIX,classIX][0][0][0]\n",
    "        y = data['trial'][dataIX,classIX][0][1][0]        \n",
    "        dataArr[classIX,dataIX,0]=x\n",
    "        dataArr[classIX,dataIX,1]=y\n",
    "MarkerPat=np.array(['rx','g+','b*'])\n",
    "\n",
    "for classIX in range(NumClass):\n",
    "    for dataIX in range(NumData):\n",
    "        plt.plot(dataArr[classIX,dataIX,0],dataArr[classIX,dataIX,1],MarkerPat[classIX])\n",
    "\n",
    "#====================================================#\n",
    "# END PLOTTING CODE\n",
    "#====================================================# \n",
    "plt.axis([0,20,0,20])\n",
    "plt.xlabel('x_1')\n",
    "plt.ylabel('x_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.  4.]\n",
      " [ 7.  3.]\n",
      " [ 7.  4.]\n",
      " [ 7.  6.]\n",
      " [ 6.  4.]\n",
      " [10. 12.]\n",
      " [17. 11.]\n",
      " [10.  5.]\n",
      " [16.  2.]\n",
      " [17.  5.]\n",
      " [ 6.  6.]\n",
      " [13.  6.]\n",
      " [ 9.  3.]\n",
      " [15.  5.]\n",
      " [ 6.  9.]\n",
      " [14.  9.]\n",
      " [22.  6.]\n",
      " [ 5.  5.]\n",
      " [10.  4.]\n",
      " [ 9.  2.]]\n",
      "[ 9.  7.  7.  7.  6. 10. 17. 10. 16. 17.  6. 13.  9. 15.  6. 14. 22.  5.\n",
      " 10.  9.]\n"
     ]
    }
   ],
   "source": [
    "#dataArr[0] gets me the first class\n",
    "#print(dataArr[0])\n",
    "#dataArr[0][0] gets me the first element of the first class\n",
    "\n",
    "c1 = dataArr[0]\n",
    "\n",
    "# first point, P(c1) = P(c2) = P(c3) because we have the same number of data points within each class\n",
    "# i.e P(c_k) = 1./3 - say this is np.array((0.33, 0.33, 0.34))\n",
    "# this is global across all of the models \n",
    "\n",
    "# for mu_k, I have a fixed scaling factor which is 1/20 (1 / NumData) and then I have the sum over all x's and separately all y's to get that ['mean'] is an np.array of size (3,2) containing the class means. -- given this shape, row1 is the mean for class 1, row2, mean for class 2 etc. therefore \n",
    "# mu_arr[0] = mu for class k \n",
    "\n",
    "## test\n",
    "\n",
    "testarraymu = np.array([[1, 2],[3, 4], [5, 6]])\n",
    "\n",
    "#print(testarraymu[0])\n",
    "\n",
    "# try and get just the x elements\n",
    "\n",
    "##### print(testarraymu[:,0])\n",
    "\n",
    "## this works. \n",
    "\n",
    "# get the means for each class \n",
    "\n",
    "# figure out how to get only the x elements for the data: \n",
    "\n",
    "print(dataArr[0])\n",
    "print(dataArr[0][:, 0])\n",
    "\n",
    "# this works. \n",
    "# print(dataArr[0][:, 0]) gets me all the x elements for my dataset. I have to find the mean of these. print(dataArr[k][:, n]) I have to loop over (k) and then over (n) for k classes and n data points. kth element will be tewstarraymu[k][0] (i.e the first column... which represents the x axis)\n",
    "\n",
    "for k in NumClass: \n",
    "    for i in NumData:\n",
    "        np.mean()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) (15 points) Find the ML model parameters\n",
    "Find the ML model parameters, for each model, using results from Problem 1. Report the values of all the ML parameters for each model. (Please print the names and values of all the ML parameters in Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#====================================================#\n",
    "# YOUR CODE HERE:\n",
    "#   Find the parameters for each model you derived in problem 1 using\n",
    "#   the simulated data, and print out the values of each parameter.\n",
    "#\n",
    "#   To facilitate plotting later on, we're going to ask you to \n",
    "#   format the data in the following way.\n",
    "#   \n",
    "#   (1) Keep three dictionaries, modParam1, modParam2, and modParam3\n",
    "#       which contain the model parameters for model 1 (Gaussian, shared cov),\n",
    "#       model 2 (Gaussian, class specific cov), and model 3 (Poisson).\n",
    "#     \n",
    "#       The Python dictionary is like a MATLAB struct. e.g., you can declare:\n",
    "#       modParam1 = {} # declares the dictionary\n",
    "#       modParam1['pi'] = np.array((0.33, 0.33, 0.34)) # sets the field 'pi' to be\n",
    "#         an np.array of size (3,) containing the class probabilities.\n",
    "#\n",
    "#   (2) modParam1 has the following structure\n",
    "#\n",
    "#     modParam1['pi'] is an np.array of size (3,) containing the class probabilities.\n",
    "#     modParam1['mean'] is an np.array of size (3,2) containing the class means.\n",
    "#     modParam1['cov'] is an np.array of size (2,2) containing the shared cov.\n",
    "#\n",
    "#   (3) modParam2: \n",
    "#\n",
    "#     modParam2['pi'] is an np.array of size (3,) containing the class probabilities.\n",
    "#     modParam2['mean'] is an np.array of size (3,2) containing the class means.\n",
    "#     modParam2['cov'] is an np.array of size (3,2,2) containing the cov for each of the 3 classes.\n",
    "#\n",
    "#   (4) modParam3:\n",
    "#     modParam2['pi'] is an np.array of size (3,) containing the class probabilities.\n",
    "#     modParam2['mean'] is an np.array of size (3,2) containing the Poisson parameters for each class.\n",
    "#\n",
    "#   These should be consistent with the print statement after this code block.\n",
    "#\n",
    "#   HINT: the np.mean and np.cov functions ought simplify the code.\n",
    "#\n",
    "#====================================================#\n",
    "\n",
    "\n",
    "#====================================================#\n",
    "# END YOUR CODE\n",
    "#====================================================# \n",
    "\n",
    "# Print out the model parameters\n",
    "print(\"Model 1:\")\n",
    "print(\"Class priors:\")\n",
    "print( modParam1['pi'])\n",
    "print(\"Means:\")\n",
    "print( modParam1['mean'])\n",
    "print(\"Cov:\")\n",
    "print( modParam1['cov'])\n",
    "\n",
    "print(\"model 2:\")\n",
    "print(\"Class priors:\")\n",
    "print( modParam2['pi'])\n",
    "print(\"Means:\")\n",
    "print( modParam2['mean'])\n",
    "print(\"Cov1:\")\n",
    "print( modParam2['cov'][0])\n",
    "print(\"Cov2:\")\n",
    "print( modParam2['cov'][1])\n",
    "print(\"Cov3:\")\n",
    "print( modParam2['cov'][2])\n",
    "\n",
    "print(\"model 3:\")\n",
    "print(\"Class priors:\")\n",
    "print( modParam3['pi'])\n",
    "print(\"Lambdas:\")\n",
    "print( modParam3['mean'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Plot the ML mean\n",
    "\n",
    "The following code plots the ML mean for each class.  You should read the code to understand what is going on.  If you followed our instructions on how to format the data, you should not have to modify any code here.  This plot needs to be generated for us to check if you implemented the means correctly.  You may also use this as a sanity check.\n",
    "\n",
    "*** If you made modifications in the way the data is formatted, you need to change this code to visualize the ML means*** \n",
    "\n",
    "For each class, we plot the ML mean on top of the data using a solid dot of the appropriate color. We set the marker size of this dot to be much larger than the marker sizes you used in part a, so the dot is easy to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# c\n",
    "plt.figure(figsize=(7,7))\n",
    "#====================================================#\n",
    "# ML MEAN PLOT CODE HERE.\n",
    "#====================================================#\n",
    "colors = ['r.','g.','b.']\n",
    "for classIX in range(NumClass):\n",
    "    for dataIX in range(NumData):\n",
    "        plt.plot(dataArr[classIX,dataIX,0],dataArr[classIX,dataIX,1],MarkerPat[classIX])\n",
    "        plt.plot(modParam1['mean'][classIX,0],modParam1['mean'][classIX,1],colors[classIX],markersize=30)\n",
    "#====================================================#\n",
    "# END CODE\n",
    "#====================================================# \n",
    "plt.axis([0,20,0,20])\n",
    "plt.xlabel('x_1')\n",
    "plt.ylabel('x_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Plot the ML covariance ellipsoids.\n",
    "\n",
    "The following code plots the ML covariance for each class.  You should read the code to understand what is going on.  If you followed our instructions on how to format the data, you should not have to modify any code here.  This plot needs to be generated for us to check if you implemented the means correctly.  You may also use this as a sanity check.\n",
    "\n",
    "*** If you made modifications in the way the data is formatted, you need to change this code to visualize the ML covariance ellipsoids*** \n",
    "\n",
    "For each class, we plot the ML covariance using an ellipse of the appropriate color. We plot this on top of the data with the means. This part only encapsulates the Gaussian models i) and ii). We generate separate plots for models i) and ii). \n",
    "\n",
    "We use of `plt.contour` can be used to draw an iso-probability contour for each class. To aid interpretation, the contour should be drawn at the same probability level for each class. We call `plt.contour(X, Y, Z, levels = level, colors = color)`. \n",
    "\n",
    "For this specific problem, we choose the contour level so you can see each ellipsoid reasonably, e.g. levels = 0.007, where X and Y are obtained via `[X,Y] = np.meshgrid(np.linspace(0, 20, N), np.linspace(0, 20, N))`, where N is the number of partitions, e.g. N = 20. Z is the function value, Please set the contour color to be the same as data points color.\n",
    "\n",
    "Please understand this code, as it will facilitate the last part of this notebook where we ask you to generate a plot with classification boundaries.  In prior years we asked the students to generate this, but have provided it here to reduce the homework load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# d\n",
    "#====================================================#\n",
    "# ML COV PLOT CODE HERE.\n",
    "#====================================================#\n",
    "colors2 = ['r','g','b']\n",
    "modParam = [modParam1 , modParam2]\n",
    "for modelIX in range(2):\n",
    "    plt.figure(modelIX,figsize=(7,7))\n",
    "    for classIX in range(NumClass):\n",
    "        for dataIX in range(NumData):\n",
    "            #plot the points and their means, just like before\n",
    "            plt.plot(dataArr[classIX,dataIX,0],dataArr[classIX,dataIX,1],MarkerPat[classIX])\n",
    "            plt.plot(modParam[modelIX]['mean'][classIX,0],modParam[modelIX]['mean'][classIX,1],colors[classIX],markersize=30)\n",
    "        plt.axis([0,20,0,20])\n",
    "        plt.xlabel('x_1')\n",
    "        plt.ylabel('x_2')\n",
    "        MarkerCol=['r','g','b']\n",
    "        \n",
    "    #now begins plotting the elipse\n",
    "    for classIX in range(NumClass):\n",
    "        currMean=modParam[modelIX]['mean'][classIX ,:]\n",
    "        if(modelIX == 0):\n",
    "            currCov=modParam[modelIX]['cov']\n",
    "        else:\n",
    "            currCov=modParam[modelIX]['cov'][classIX]\n",
    "        xl = np.linspace(0, 20, 201)\n",
    "        yl = np.linspace(0, 20, 201)\n",
    "        [X,Y] = np.meshgrid(xl,yl)\n",
    "\n",
    "        Xlong = np.reshape(X-currMean[0],(np.prod(np.size(X))))\n",
    "        Ylong = np.reshape(Y-currMean[1],(np.prod(np.size(X))))\n",
    "        temp = np.row_stack([Xlong,Ylong])\n",
    "        Zlong = []\n",
    "        for i in range(np.size(Xlong)):\n",
    "            Zlong.append(np.matmul(np.matmul(temp[:,i], np.linalg.inv(currCov)), temp[:,i].T))\n",
    "        Zlong = np.matrix(Zlong)\n",
    "        Zlong = np.exp(-Zlong/2)/np.sqrt((2*np.pi)*(2*np.pi)*np.linalg.det(currCov))\n",
    "        Z = np.reshape(Zlong,X.shape)\n",
    "        isoThr=0.007\n",
    "        plt.contour(X,Y,Z,levels = isoThr,colors = colors2[classIX])\n",
    "#====================================================#\n",
    "# END CODE\n",
    "#====================================================# \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) (15 points) Plot multi-class decision boundaries\n",
    "Plot multi-class decision boundaries corresponding to the decision rule \n",
    "\\begin{align}            \n",
    "    \\hat{k }=argmax_{k} \\ P(C_{k}|x)\n",
    "\\end{align}\n",
    "and label each decision region with the appropriate class k. This should be plotted on top of your means and the covariance ellipsoids. Thus, you should start by copying and pasting code from the prior Jupyter Notebook cell.\n",
    "\n",
    "To plot the multi-class decision boundaries, we recommend that you do it by classifying a dense sampling of the two-dimensional data space.\n",
    "\n",
    "Hint 1: You can do this by calling `[X,Y] = np.meshgrid(np.linspace(0, 20, N), np.linspace(0, 20, N))` to partition the space as done in the previous section, and then classifying each of these points.  N should be large; in our solution, we use N = 81.  Then at each of these points, draw a dot of the color of the classified class.\n",
    "\n",
    "Hint 2: You can check that you’ve done this properly by verifying that the decision boundaries pass through the intersection points of the contours drawn in part (d).\n",
    "\n",
    "Hint 3: It's a good idea to do this one model at a time. You should get things working for model 1 for a smaller `N` value, so in code development, it doesn't take a long time to test your code.  In the final result, your code will probably take some time to run because you're classifying each data point in a dense grid for each model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#e\n",
    "#====================================================#\n",
    "# YOUR CODE HERE:\n",
    "#   Plot the data points, their means, covariance ellipsoids,\n",
    "#     and decision boundaries for each model.\n",
    "#   Note that the naive Bayes Poisson model does not have an ellipsoid.\n",
    "#   As in the above description, the decision boundary should be achieved\n",
    "#     by densely classifying points in a grid.\n",
    "#====================================================#\n",
    "\n",
    "#====================================================#\n",
    "# END YOUR CODE\n",
    "#====================================================#     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b09acc547dda0abba2c23fcb8d82975ee324aece1a65962f9bf2d993acca7b61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
